{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wcngai/colabs/blob/main/CodeFormer_inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjdQE0kKcqjA"
      },
      "source": [
        "<p align=\"center\">\n",
        "  <img src=\"https://user-images.githubusercontent.com/14334509/179359809-bd45566a-486d-418f-83fa-67bbbba8c45c.png\" height=120>\n",
        "</p>\n",
        "\n",
        "# CodeFormer Inference Demo \n",
        "## Towards Robust Blind Face Restoration with Codebook Lookup Transformer (NeurIPS 2022)\n",
        "Shangchen Zhou, Kelvin C.K. Chan, Chongyi Li, Chen Change Loy\n",
        "\n",
        "[![GitHub Stars](https://img.shields.io/github/stars/sczhou/CodeFormer?style=social)](https://github.com/sczhou/CodeFormer) [![arXiv](https://img.shields.io/badge/arXiv-Paper-<COLOR>.svg)](https://arxiv.org/abs/2206.11253) [![Hugging Face](https://img.shields.io/badge/Demo-%F0%9F%A4%97%20Hugging%20Face-blue)](https://huggingface.co/spaces/sczhou/CodeFormer) ![visitors](https://visitor-badge.glitch.me/badge?page_id=sczhou/CodeFormer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_U5Bu-qie_aH"
      },
      "source": [
        "# 1. Preparations\n",
        "Before start, make sure that you choose\n",
        "* Hardware Accelerator = GPU (in the Runtime menu -> Change runtime type)\n",
        "\n",
        "Then, we clone the repository, set up the envrironment, and download the pre-trained model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SG9AcLQO_FQ"
      },
      "outputs": [],
      "source": [
        "# Clone CodeFormer and enter the CodeFormer folder\n",
        "%cd /content\n",
        "!rm -rf CodeFormer\n",
        "!git clone https://github.com/sczhou/CodeFormer.git\n",
        "%cd CodeFormer\n",
        "\n",
        "# Set up the environment\n",
        "# Install python dependencies\n",
        "!pip install -r requirements.txt\n",
        "# Install basicsr\n",
        "!python basicsr/setup.py develop\n",
        "\n",
        "# Download the pre-trained model\n",
        "!python scripts/download_pretrained_models.py facelib\n",
        "!python scripts/download_pretrained_models.py CodeFormer\n",
        "\n",
        "# Visualization function\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "def display(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1) \n",
        "  plt.title('Input', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title('CodeFormer', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzLAguVdix6_"
      },
      "source": [
        "&nbsp;\n",
        "***\n",
        "&nbsp;\n",
        "# 2. Test on your images ðŸ˜€\n",
        "\n",
        "*   Old photos\n",
        "*   AI-created face images by DALLE2/Midjourney/Stable Diffusion\n",
        "\n",
        "If CodeFormer is helpful to your photos, please help star our [repo](https://github.com/sczhou/CodeFormer). Thanks! ðŸ¤— \n",
        "\n",
        "[![GitHub Stars](https://img.shields.io/github/stars/sczhou/CodeFormer?style=social)](https://github.com/sczhou/CodeFormer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DK3esrSmiziX"
      },
      "outputs": [],
      "source": [
        "# Upload your own images\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "upload_folder = 'inputs/user_upload'\n",
        "\n",
        "if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "os.mkdir(upload_folder)\n",
        "\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  dst_path = os.path.join(upload_folder, filename)\n",
        "  print(f'move {filename} to {dst_path}')\n",
        "  shutil.move(filename, dst_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cj2YQGg3J0TQ"
      },
      "outputs": [],
      "source": [
        "# Inference the uploaded images\n",
        "#@markdown `CODEFORMER_FIDELITY`: Balance the quality (lower number) and fidelity (higher number)<br>\n",
        "# you can add '--bg_upsampler realesrgan' to enhance the background\n",
        "CODEFORMER_FIDELITY = 0.75 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "#@markdown `BACKGROUND_ENHANCE`: Enhance background image with Real-ESRGAN<br>\n",
        "BACKGROUND_ENHANCE = False #@param {type:\"boolean\"}\n",
        "#@markdown `FACE_UPSAMPLE`: Upsample restored faces for high-resolution AI-created images<br>\n",
        "FACE_UPSAMPLE = False #@param {type:\"boolean\"}\n",
        "if BACKGROUND_ENHANCE:\n",
        "  if FACE_UPSAMPLE:\n",
        "    !python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path inputs/user_upload --bg_upsampler realesrgan --face_upsample\n",
        "  else:\n",
        "    !python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path inputs/user_upload --bg_upsampler realesrgan\n",
        "else:\n",
        "  !python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path inputs/user_upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4hauJLwIQQV"
      },
      "outputs": [],
      "source": [
        "# Visualize the results\n",
        "import os\n",
        "import glob\n",
        "\n",
        "input_folder = 'inputs/user_upload'\n",
        "result_folder = f'results/user_upload_{CODEFORMER_FIDELITY}/final_results'\n",
        "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "for input_path in input_list:\n",
        "  img_input = imread(input_path)\n",
        "  basename = os.path.splitext(os.path.basename(input_path))[0]\n",
        "  output_path = os.path.join(result_folder, basename+'.png')\n",
        "  img_output = imread(output_path) \n",
        "  display(img_input, img_output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download results\n",
        "!ls results\n",
        "print('Download results')\n",
        "os.system(f'zip -r results.zip results/user_upload_{CODEFORMER_FIDELITY}/final_results')\n",
        "files.download(\"results.zip\")"
      ],
      "metadata": {
        "id": "0RRKl1iDMpVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72f3GJtIFZtf"
      },
      "source": [
        "&nbsp;\n",
        "***\n",
        "&nbsp;\n",
        "# 3. Inference on the demo images (whole images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d6CkQ2x-eSjH"
      },
      "outputs": [],
      "source": [
        "# We set w to 0.7 for the whole images\n",
        "# you can add '--bg_upsampler realesrgan' to enhance the background\n",
        "CODEFORMER_FIDELITY = 0.7\n",
        "\n",
        "## Below is original code\n",
        "##!python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path inputs/whole_imgs --bg_upsampler realesrgan\n",
        "\n",
        "!python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path inputs/user_upload --bg_upsampler realesrgan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kG2mlYMjF8mQ"
      },
      "outputs": [],
      "source": [
        "# Visualize the results\n",
        "import os\n",
        "import glob\n",
        "\n",
        "## Below is original code\n",
        "##input_folder = 'inputs/whole_imgs'\n",
        "##result_folder = f'results/whole_imgs_{w}/final_results'\n",
        "\n",
        "input_folder = 'inputs/user_upload'\n",
        "result_folder = f'results/user_upload/final_results'\n",
        "\n",
        "\n",
        "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n",
        "for input_path, output_path in zip(input_list, output_list):\n",
        "  img_input = imread(input_path)\n",
        "  img_output = imread(output_path)\n",
        "  display(img_input, img_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrUil37TjFGR"
      },
      "source": [
        "&nbsp;\n",
        "***\n",
        "&nbsp;\n",
        "# 4. Inference on the demo faces (croped and aligned faces)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJy16AUOjLkO"
      },
      "outputs": [],
      "source": [
        "!rm -rf results\n",
        "\n",
        "# We set w to 0.5 for the cropped and aligned faces\n",
        "CODEFORMER_FIDELITY = 0.5\n",
        "\n",
        "## Below is original code\n",
        "##!python inference_codeformer.py -w $CODEFORMER_FIDELITY --has_aligned --input_path inputs/cropped_faces\n",
        "\n",
        "!python inference_codeformer.py -w $CODEFORMER_FIDELITY --has_aligned --input_path inputs/user_upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1E9DHUt_k_I"
      },
      "outputs": [],
      "source": [
        "# Visualize the results\n",
        "import os\n",
        "import glob\n",
        "\n",
        "## Below is original code\n",
        "## input_folder = 'inputs/cropped_faces'\n",
        "## result_folder = f'results/cropped_faces_{w}/restored_faces'\n",
        "\n",
        "input_folder = 'inputs/user_upload'\n",
        "result_folder = f'results/user_upload/restored_faces'\n",
        "\n",
        "input_list = sorted(glob.glob(os.path.join(input_folder, '*')))\n",
        "output_list = sorted(glob.glob(os.path.join(result_folder, '*')))\n",
        "for input_path, output_path in zip(input_list, output_list):\n",
        "  img_input = imread(input_path)\n",
        "  img_output = imread(output_path)\n",
        "  display(img_input, img_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAVowOigwBzZ"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;\n",
        "***\n",
        "&nbsp;\n",
        "# 5. Inference Videos\n"
      ],
      "metadata": {
        "id": "F3cVQcklXc3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##!pip3 install ffmpeg-python\n",
        "##import ffmpeg\n",
        "\n",
        "!apt install ffmpeg\n",
        "#!pip install ffmpeg\n",
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "id": "D5W1mBzRZemx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;\n",
        "****\n",
        "&nbsp;\n",
        "## 5.1 Option 1: Upload Individual video"
      ],
      "metadata": {
        "id": "9ZG07mWGmA0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Option 1: Upload Individual video\n",
        "import os\n",
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "upload_folder = 'inputs/user_videos'\n",
        "\n",
        "if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "os.mkdir(upload_folder)\n",
        "\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "  dst_path = os.path.join(upload_folder, filename)\n",
        "  print(f'move {filename} to {dst_path}')\n",
        "  shutil.move(filename, dst_path)"
      ],
      "metadata": {
        "id": "4rlyokp3jPcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "&nbsp;\n",
        "****\n",
        "&nbsp;\n",
        "## 5.2 Option 2: Copy videos from Google Drive: Short_Flim/Preprocess "
      ],
      "metadata": {
        "id": "eZb53YIpmM1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#### Option 2: Copy videos from Short_Flim/Preprocess \n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "from os.path import isfile, join\n",
        "#import shutil\n",
        "\n",
        "# Mounting Google Drive: Mounted at /content/drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy all video files\n",
        "!mkdir inputs/user_videos\n",
        "#!rm -rf inputs/user_videos\n",
        "!cp -r /content/drive/MyDrive/Short_Flims/Preprocess/. /content/CodeFormer/inputs/user_videos/.\n",
        "\n",
        "# Clean up previous results\n",
        "!rm -rf results\n",
        "\n",
        "# Process all video files\n",
        "CODEFORMER_FIDELITY = 0.7\n",
        "FOLDER_NAME = \"inputs/user_videos/\"\n",
        "\n",
        "for filename in os.listdir(FOLDER_NAME):\n",
        "\n",
        "  fullpath = os.path.join(FOLDER_NAME, filename)\n",
        "  ## output sample: inputs/user_videos/filename.mp4\n",
        "\n",
        "  if (isfile(fullpath)):\n",
        "    print(f'==================================Processing: {fullpath}')\n",
        "##    !python inference_codeformer.py --face_upsample -w $CODEFORMER_FIDELITY --bg_upsampler realesrgan --input_path $fullpath\n",
        "    !python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path $fullpath\n"
      ],
      "metadata": {
        "id": "2v4mtp3DU1Aj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O5W5FnktiN5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode and Export file to the processes folder\n",
        "\n",
        "#!ffmpeg -i results/VID_20230102_000536_130_0.2/VID_20230102_000536_130.mp4 -vf \"crop=trunc(iw/16)*16:trunc(ih/16)*16\" results/VID_20230102_000536_130_0.2/VID_20230102_000536_130_0.2_e.mp4\n",
        "\n",
        "OUTPUT_FOLDER_PATH = 'results'\n",
        "OUTPUT_GOOGLE_DRIVE_PREPOST = \"/content/drive/MyDrive/Short_Flims/Prepost/.\"\n",
        "OUTPUT_GOOGLE_DRIVE_PROCESSED = \"/content/drive/MyDrive/Short_Flims/Postprocess_NOT_FOR_POSTING/.\"\n",
        "\n",
        "for output_folder in os.listdir(OUTPUT_FOLDER_PATH):\n",
        "  fullpath = os.path.join(OUTPUT_FOLDER_PATH, output_folder)\n",
        "  # results/<video_name>_<0.8>\n",
        "\n",
        "  for output_file in os.listdir(fullpath):\n",
        "    output_file_fullname = os.path.join(fullpath, output_file)\n",
        "    # results/<video_name>_0.8/<video_name>.mp4\n",
        "\n",
        "    if (isfile(output_file_fullname)):\n",
        "      #filename_noext = os.path.splitext(output_file)[0]\n",
        "      #filename_ext = os.path.splitext(output_file)[1]\n",
        "      filename_encoded = fullpath + '/' + os.path.splitext(output_file)[0] + '_e' + os.path.splitext(output_file)[1]\n",
        "      #print(f'{filename_encoded}')\n",
        "\n",
        "      print(f'Encoding file: {output_file_fullname}')\n",
        "      !ffmpeg -i $output_file_fullname -vf \"crop=trunc(iw/16)*16:trunc(ih/16)*16\" $filename_encoded\n",
        "      \n",
        "      print(f'Copying files to Goole Drive: {filename_encoded}')\n",
        "      !cp -r $filename_encoded $OUTPUT_GOOGLE_DRIVE_PREPOST\n",
        "      !cp -r $filename_encoded $OUTPUT_GOOGLE_DRIVE_PROCESSED\n"
      ],
      "metadata": {
        "id": "TYxmdfz4AlPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download results\n",
        "!ls results\n",
        "print('Download results')\n",
        "\n",
        "DOWNLOAD_FILE_PATH = \"results/Snaptik_121_0.2/\"\n",
        "DOWNLOAD_FILE_NAME = \"Snaptik_121.mp4\"\n",
        "\n",
        "os.system(f'zip -r {DOWNLOAD_FILE_NAME}.zip {DOWNLOAD_FILE_PATH}{DOWNLOAD_FILE_NAME}')\n",
        "files.download(f'{DOWNLOAD_FILE_NAME}.zip')"
      ],
      "metadata": {
        "id": "J7CdrnXjsAiu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "_U5Bu-qie_aH",
        "GzLAguVdix6_",
        "72f3GJtIFZtf",
        "UrUil37TjFGR",
        "9ZG07mWGmA0h"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}